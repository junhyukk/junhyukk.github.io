<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">    
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.min.css">
    <link rel="stylesheet" href="css/junhyuk.css">
    <title>Jun-Hyuk Kim</title>
  </head>

  <body data-spy="scroll" data-target="#my_navbar" data-offset="90">

    <!-- Navigaton bar -->
    <nav class="shadow-sm navbar navbar-expand-lg navbar-light bg-light fixed-top" id="my_navbar">
      <div class="container">
        <!-- Navigaton brand -->
        <a class="navbar-brand font-weight-bold" href="#">Jun-Hyuk Kim</a>
        <a class="navbar-brand" href="http://scholar.google.com/citations?user=A0io6mQAAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i></a>
        <a class="navbar-brand" href="http://github.com/junhyukk/" target="_blank"><i class="fab fa-github"></i></a>
        <a class="navbar-brand mr-auto" href="CV.pdf" target="_blank"><i class="fas fa-file-pdf"></i></a>

        <!-- Navtigation toggler button-->
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#my_navbar_contents" aria-controls="my_navbar_contents" aria-expanded="false" aria-label="Toggle navigation">
          <span ><i class="fas fa-bars"></i></span>
        </button>

        <!-- Navtigation toggler contents -->
        <div class="collapse navbar-collapse" id="my_navbar_contents">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item" data-toggle="collapse" data-target=".navbar-collapse.show">
              <a class="nav-link" href="#home"><strong>Home</strong></a>
            </li>
            <li class="nav-item" data-toggle="collapse" data-target=".navbar-collapse.show">
              <a class="nav-link" href="#publications"><strong>Publications</strong></a>
            </li>
            <li class="nav-item" data-toggle="collapse" data-target=".navbar-collapse.show">
              <a class="nav-link" href="#awards"><strong>Awards</strong></a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Section: home -->
    <section class="container section" id="home">
      <div class="row align-items-center">
        <div class="col-md-4 text-center">
          <img src="junhyuk_kim.jpg" class="border-7 rounded-circle w-75">
          <div class="pt-1 pb-3">
            <h3>Jun-Hyuk Kim</h3>
            <h4 class="lead font-weight-normal">Ph.D. student</h4>
            <h4 class="lead font-weight-light">junhyuk.kim@yonsei.ac.kr</h4>
          </div>
        </div>
        <div class="col-md-8">
          <p class="lead font-weight-normal">
            I am a PhD student at the <a href="http://mcml.yonsei.ac.kr/" target="_blank">Multimedia Computing and Machine Learning (MCML) Group</a> of <a href="https://www.yonsei.ac.kr/en_sc/" target="_blank">Yonsei University</a> under the supervision of Prof. Jong-Seok Lee. I received the B.S. degree in the <a href="http://sit.yonsei.ac.kr/" target="_blank">School of Integrated Technology</a> from Yonsei University, South Korea, in 2015. My research interests include low-level computer vision and deep learning.
          </p>    
        </div>
      </div>
      <hr width="100%" align="left" color="#EAECEE">
    </section>

    <!-- Section: publications -->
    <section class="container section" id="publications">
      <h2><i class="fas fa-newspaper"></i> Publications</h2>
      
      <!-- Sub-section: preprints -->
<!--       <section class="sub-section">      
        <h3><li><span>Preprints</span></li></h3>
        <p class="publication-item">
          <span class="lead">Lightweight and efficient image super-resolution with block state-based recursive network</span><br />
          J.-H. Choi, <strong>J.-H. Kim</strong>, M. Cheon, J.-S. Lee<br />
          <em>arXiv:1811.12546</em>, Nov. 2018<br />
          <a href="https://arxiv.org/abs/1811.12546" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a> / <a href="https://github.com/idearibosome/tf-bsrn-sr" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
      </section> -->

      <!-- Sub-section: journals -->
      <section class="sub-section">      
        <h3><li><span>Journals</span></li></h3>
        <p class="publication-item">
          <span class="lead">Volatile-nonvolatile memory network for progressive image super-resolution</span><br />
          J.-H. Choi, <strong>J.-H. Kim</strong>, M. Cheon, J.-S. Lee<br />
          <em>IEEE Access</em>, vol. 9, pp. 37487-37496, Mar. 2021<br />
          <a href="https://doi.org/10.1109/ACCESS.2021.3063760" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / <a href="https://github.com/idearibosome/tf-vmnet" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="publication-item">
          <span class="lead">MAMNet: Multi-path adaptive modulation network for image super-resolution</span><br />
          <strong>J.-H. Kim</strong>, J.-H. Choi, M. Cheon, J.-S. Lee<br />
          <em>Neurocomputing</em>, vol. 402, pp. 38-49, Aug. 2020<br />
          <a href="https://doi.org/10.1016/j.neucom.2020.03.069" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / <a href="https://arxiv.org/abs/1811.12043" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a> / <a href="https://github.com/junhyukk/MAMNet-tensorflow" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="publication-item">
          <span class="lead">Deep learning-based image super-resolution considering quantitative and perceptual quality</span><br />
          J.-H. Choi, <strong>J.-H. Kim</strong>, M. Cheon, J.-S. Lee<br />
          <em>Neurocomputing</em>, vol. 398, pp. 347-359, Jul. 2020<br />
          <a href="https://doi.org/10.1016/j.neucom.2019.06.103" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / 
          <a href="https://arxiv.org/abs/1809.04789" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a> / <a href="https://github.com/idearibosome/tf-perceptual-eusr" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>    
        <p class="publication-item">
          <span class="lead">Prediction of car design perception using EEG and gaze patterns</span><br />
          S.-E. Moon, <strong>J.-H. Kim</strong>, S.-W. Kim, J.-S. Lee<br />
          <em>IEEE Transactions on Affective Computing</em>, accepted<br />
          <a href="https://doi.org/10.1109/TAFFC.2019.2901733" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>  
      </section>

      <!-- Sub-section: conferences -->   
      <section class="sub-section">      
        <h3><li><span>Conferences</span></li></h3>
        <p class="publication-item">
          <span class="lead">Adversarially robust deep image super-resolution using entropy regularization</span><br />
          J.-H. Choi, H. Zhang, <strong>J.-H. Kim</strong>, C.-J. Hsieh, J.-S. Lee<br />
          <em>Asian Conference on Computer Vision (ACCV)</em>, Nov. 2020<br />
          <a href="https://openaccess.thecvf.com/content/ACCV2020/html/Choi_Adversarially_Robust_Deep_Image_Super-Resolution_using_Entropy_Regularization_ACCV_2020_paper.html" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Multi-scale adaptive residual network using total variation for real image super-resolution</span><br />
          K.-H. Ahn, <strong>J.-H. Kim</strong>, J.-H. Choi, J.-S. Lee<br />
          <em>International Conference on Consumer Electronics Asia (ICCE-Asia)</em>, pp. 349-352, Nov. 2020<br />
          <a href="https://doi.org/10.1109/ICCE-Asia49877.2020.9276925" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Efficient bokeh effect rendering using generative adversarial network</span><br />
          M.-S. Choi, <strong>J.-H. Kim</strong>, J.-H. Choi, J.-S. Lee<br />
          <em>International Conference on Consumer Electronics Asia (ICCE-Asia)</em>, pp. 404-408, Nov. 2020<br />
          <a href="https://doi.org/10.1109/ICCE-Asia49877.2020.9276807" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Instability of successive deep image compression</span><br />
          <strong>J.-H. Kim</strong>, S. Jang, J.-H. Choi, J.-S. Lee<br />
          <em>ACM Multimedia (MM)</em>, pp. 247-255, Oct. 2020<br />
          <a href="https://doi.org/10.1145/3394171.3413680" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">LarvaNet: hierarchical super-resolution via multi-exit architecture</span><br />
          G.-W. Jeon, J.-H. Choi, <strong>J.-H. Kim</strong>, J.-S. Lee<br />
          <em>European Conference on Computer Vision (ECCV) Workshops</em>, Aug. 2020<br />
          <a href="https://doi.org/10.1007/978-3-030-67070-2_4" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">AIM 2020 challenge on efficient super-resolution: methods and results</span><br />
          K. Zhang et al. (including <strong>J.-H. Kim</strong>)<br />
          <em>European Conference on Computer Vision (ECCV) Workshops</em>, Aug. 2020<br />
          <a href="https://arxiv.org/abs/2009.06943" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a>
        </p>
        <p class="publication-item">
          <span class="lead">AIM 2020 challenge on real image super-resolution: methods and results</span><br />
          P. Wei et al. (including <strong>J.-H. Kim</strong>)<br />
          <em>European Conference on Computer Vision (ECCV) Workshops</em>, Aug. 2020<br />
          <a href="https://arxiv.org/abs/2009.12072" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a>
        </p>
        <p class="publication-item">
          <span class="lead">Efficient deep learning-based lossy image compression via asymmetric autoencoder and pruning</span><br />
          <strong>J.-H. Kim</strong>, J.-H. Choi, J. Chang, J.-S. Lee<br />
          <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 2063-2067, May 2020<br />
          <a href="https://doi.org/10.1109/ICASSP40776.2020.9053102" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">SRZoo: An integrated repository for super-resolution using deep learning</span><br />
          J.-H. Choi, <strong>J.-H. Kim</strong>, J.-S. Lee<br />
          <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 2508-2512, May 2020<br />
          <a href="https://doi.org/10.1109/ICASSP40776.2020.9054533" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> /
          <a href="https://github.com/idearibosome/srzoo" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="publication-item">
          <span class="lead">Evaluating robustness of deep image super-resolution against adversarial attacks</span><br />
          J.-H. Choi, H. Zhang, <strong>J.-H. Kim</strong>, C.-J. Hsieh, J.-S. Lee<br />
          <em>IEEE International Conference on Computer Vision (ICCV)</em>, pp. 303-311, Oct. 2019<br />
          <a href="http://openaccess.thecvf.com/content_ICCV_2019/html/Choi_Evaluating_Robustness_of_Deep_Image_Super-Resolution_Against_Adversarial_Attacks_ICCV_2019_paper.html" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / <a href="https://arxiv.org/abs/1904.06097" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a>
        </p>
        <p class="publication-item">
          <span class="lead">Deep learning-based super-resolution for digital comics</span><br />
          <strong>J.-H. Kim</strong>, J.-H. Choi, C.-H. Seo, J. Chang, J.-S. Lee<br />
          <em>SIGGRAPH Asia 2018 Posters</em>, Article 19, Dec. 2018<br />
          <a href="https://doi.org/10.1145/3283289.3283337" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Generative adversarial network-based image super-resolution using perceptual content losses</span><br />
          M. Cheon, <strong>J.-H. Kim</strong>, J.-H. Choi, J.-S. Lee<br />
          <em>European Conference on Computer Vision (ECCV) Workshops</em>, pp. 51-62, Sep. 2018<br />
          <a href="https://doi.org/10.1007/978-3-030-11021-5_4" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / <a href="http://arxiv.org/abs/1809.04783" target="_blank"><i class="fas fa-external-link-square-alt"></i> arXiv</a> / <a href="https://github.com/manricheon/eusr-pcl-tf" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="publication-item">
          <span class="lead">Deep residual network with enhanced upscaling module for super-resolution</span><br />
          <strong>J.-H. Kim</strong>, J.-S. Lee<br />
          <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, pp. 913-921, Jun. 2018<br />
          <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/w13/html/Kim_Deep_Residual_Network_CVPR_2018_paper.html" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a> / <a href="https://github.com/junhyukk/EUSR-Tensorflow" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="publication-item">
          <span class="lead">NTIRE 2018 challenge on single image super-resolution: methods and results</span><br />
          R. Timofte et al. (including <strong>J.-H. Kim</strong>)<br />
          <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, pp. 965-976, Jun. 2018<br />
          <a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/w13/html/Timofte_NTIRE_2018_Challenge_CVPR_2018_paper.html" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Assessing product design using photos and real products</span><br />
          S.-E. Moon, <strong>J.-H. Kim</strong>, S.-W. Kim, J.-S. Lee<br />
          <em>ACM Conf. Human Factors in Computing Systems (CHI), Extended Abstract</em>, pp. 1100-1107, May 2017<br />
          <a href="https://doi.org/10.1145/3027063.3053336" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
        <p class="publication-item">
          <span class="lead">Travel photo album summarization based on aesthetic quality, interestingness, and memorableness</span><br />
          <strong>J.-H. Kim</strong>, J.-S. Lee<br />
          <em>APSIPA Annual Summit and Conference</em>, Dec. 2016<br />
          <a href="https://doi.org/10.1109/APSIPA.2016.7820889" target="_blank"><i class="fas fa-external-link-square-alt"></i> Detail</a>
        </p>
      </section>
    </section>

    <!-- Section: awards -->
    <section class="container section" id="awards">
      <h2><i class="fas fa-award"></i> Awards</h2>
      <section class="sub-section">   
        <p class="award-item">
          <span class="lead">Merit Academic Paper Award</span><br />
          <em>2020-2 Yonsei Superior Paper Awards</em>, Dec. 2020<br />
          <small>Korean: 2020년 2학기 연세대학교 대학원생 우수논문 장려상</small>
        </p>   
        <p class="award-item">
          <span class="lead">2nd Place (Region 1)</span><br />
          Yonsei-MCML team<br />
          <em>Super-Resolution Challenge on Perceptual Image Restoration and Manipulation (PIRM)</em>, in conjunction with ECCV, Sep. 2018<br />
          <a href="https://www.pirm2018.org/PIRM-SR.html#leaderboard" target="_blank"><i class="fas fa-external-link-square-alt"></i> Leaderboard</a> / <a href="https://github.com/manricheon/eusr-pcl-tf" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
        <p class="award-item">
          <span class="lead">2nd Place (Region 2)</span><br />
          Yonsei-MCML team<br />
          <em>Super-Resolution Challenge on Perceptual Image Restoration and Manipulation (PIRM)</em>, in conjunction with ECCV, Sep. 2018<br />
          <a href="https://www.pirm2018.org/PIRM-SR.html#leaderboard" target="_blank"><i class="fas fa-external-link-square-alt"></i> Leaderboard</a> / <a href="https://github.com/idearibosome/tf-perceptual-eusr" target="_blank"><i class="fab fa-github"></i> GitHub</a>
        </p>
      </section>
    </section>

    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

  </body>
</html>
